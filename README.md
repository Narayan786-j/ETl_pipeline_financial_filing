ğŸ“Œ Project Overview

This project is an ETL (Extract, Transform, Load) pipeline designed to process financial filings (HTML/PDF).
It extracts structured tables (Balance Sheet, Income Statement), cleans and standardizes them, applies data quality checks, and prepares the data for downstream analytics.

The pipeline is fully Dockerized for portability and reproducibility.

ğŸš€ Features

âœ… Parse HTML and PDF filings

âœ… Extract multi-page / multi-row header tables

âœ… Normalize metrics (e.g., Net Income vs Net Earnings)

âœ… Ensure consistent units (USD millions)

âœ… Apply 5+ quality checks

âœ… Read from input_file.txt

âœ… Containerized with Docker

ğŸ—ï¸ Project Structure

ETL_python/

â”‚â”€â”€ main.py                # Entry point of the ETL pipeline

â”‚â”€â”€ functions.py           # helper funcions

â”‚â”€â”€ logger.py              # debug log generator

â”‚â”€â”€ OLTP.py                # OLTP data processing

â”‚â”€â”€ OLAP.py                # loading OLTP data to OLAP for analytics

â”‚â”€â”€ requirements.txt       # Python dependencies

â”‚â”€â”€ Dockerfile             # Docker build instructions

â”‚â”€â”€ input_file.txt         # List of filings to process

â”‚â”€â”€ etl_debug.log          # Logs generated by pipeline

âš™ï¸ Setup & Installation

1ï¸âƒ£ Clone the Repository

git clone https://github.com/yourusername/etl_pipeline.git
cd etl_pipeline

2ï¸âƒ£ Install Dependencies (optional if not using Docker)

pip install -r requirements.txt

ğŸ³ Running with Docker

Build Image
docker build -t etl_pipeline:latest .

Run Container
docker run --rm -it -v "C:\Users\NARAYAN JHA\Downloads\Assignment_Jr_Data_Engineer\Assignment_Jr_Data_Engineer:/app/data" etl_pipeline:latest


Input files: listed inside input_file.txt
Output files: stored in /app/output (map with -v for local access)

ğŸ“‚ Input File Format (input_file.txt)

Each line contains a path to a filing.
Lines starting with # are treated as comments and skipped.

Example:

# Example SEC filings list

data/EWCZ_20250813_PR.html

data/ACHR_20250811_PR.pdf

âœ… Data Quality Checks

The pipeline enforces:

No duplicate primary keys

No future dates

Revenue > 0

Required metrics must exist

Completeness check for numeric columns

ğŸ“Š Example Logs

2025-08-31 06:30:45,671 - INFO - Processing file: /app/data/EWCZ_20250813_PR.html

2025-08-31 06:30:45,671 - WARNING - Skipping unsupported file type: /app/data/ACHR_20250811_PR.pdf

2025-08-31 06:30:46,100 - INFO - Successfully extracted Balance Sheet

ğŸ”® Future Improvements

Add OCR for scanned PDFs,
Store processed data in SQLite/Postgres,
Build a dashboard for analytics

Add CI/CD pipeline for automation

ğŸ‘¨â€ğŸ’» Author

Narayan Jha

Associate Data Engineer | Big Data & FastAPI Enthusiast
